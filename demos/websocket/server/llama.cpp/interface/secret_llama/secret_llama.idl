// Copyright (c) 2026 Edward Boggis-Rolfe
// All rights reserved.

// this is code kindly provided by Cedric Wahl as part of source code from secretarium
// its internal project name was secret_llama and was used to demonstrate the use of 
// llms inside TEEs
// this is smashed in for a demo


// #import "json/json.idl"

namespace secret_llama
{
    [inline] namespace v1_0
    {
        enum error_types : int
        {
            OK,                 //note transaction functions and stateless funcitons that are in a transaction always return 0
            //splicded in from llama2.c
            // OK 0
            OUT_OF_MEMORY, // 1
            BAD_MAGIC_NUMBER, // 2
            BAD_VERSION, // 3
            BAD_CLASSIFIER, // 4
            BAD_GROUP_SIZE, // 5
            TOO_SMALL, // 6
            INVALID_PRINTF, // 7
            CANNOT_ENCODE_NULL_TEXT, // 8
            UNKNOWN_ERROR, // 9
            
            LLM_STILL_PROCESSING, // 10 llama2.c extension
            LLM_NEEDS_USER_INPUT, // 11 llama2.c extension
            LLM_STEPS_EXHAUSTED, // 12 llama2.c extension
            
            // and the rest
            UNABLE_TO_LOAD_RNG,
            RANDOM_NUMBER_GENERATOR_FAILED,
            NOT_IMPLEMENTED,
            MODEL_NOT_LOADED,
            TOKENIZER_NOT_LOADED,
            TOKENIZER_FAULT,
            INVALID_CONTEXT,
            INVALID_PROMPT,
            NOT_LOGGED_IN,
            PERMISSION_DENIED,
            UNABLE_TO_SAVE_RECORD,
            UNABLE_TO_LOAD_RECORD,
            UNABLE_TO_GET_PIECE,
            UNABLE_TO_DECODE,
            UNABLE_TO_LOAD_MODEL,
            UNABLE_TO_REMOVE_RECORD,
            UNABLE_TO_LIST_RECORDS,
            UNABLE_TO_LIST_KEYS,
            UNABLE_TO_LOAD_FILE_SYSTEM,
            UNABLE_TO_LIST_FILES,
            UNABLE_TO_REMOVE_FILE,
            UNABLE_TO_DOWNLOAD_FILE,
            UNABLE_TO_GET_DOWNLOAD_STATUS,
            UNABLE_TO_GET_SENDER,
            UNABLE_TO_MAP_FILE,
            UNABLE_TO_TOKENIZE,
            ADMIN_ACCOUNT_MUST_BE_ADMINISTRATOR,
            ACCOUNT_ALREADY_EXISTS,
            ACCOUNT_NOT_FOUND,
            MAX_USER_CONTEXTS_EXCEEDED,  // per user
            MAX_CONTEXTS_EXCEEDED,       // all users
            UNABLE_TO_CREATE_TIMEOUT,
            CONTEXT_EXPIRED,
            CONTEXT_NOT_FINISHED,
            CONTEXT_MISSING,
            CONTEXT_SIZE_EXCEEDED,
            MODEL_FAILED,
            ENGINE_NOT_LOADED,
            DECODE_FAILURE,
            UNABLE_TO_CONVERT_TOKEN_TO_PIECE,
            UNABLE_TO_APPLY_CHAT_TEMPLATE,
            EXCEPTION_THROWN,
            CALLBACK_ALREADY_ASSIGNED,
            CALLBACK_NOT_ASSIGNED,

            ERROR_TYPES_SENTINEL = 2147483647 //max int sentinel value
        };

        //a description per error code
        /*std::array<std::string> error_descriptions
        {
            "OK",                           //OK,                   note transaction functions and stateless funcitons that are in a transaction always return 0
            "Record not found",            //RECORD_NOT_FOUND     the record is not found
            "No more records",            //NO_MORE_RECORDS     the record is not found
        }*/
        
        #cpp_quote(R^multiline(
            inline static int to_standard_return_type(error_types err) {return static_cast<int>(err);}
            
        )multiline^)
        
        // yup we may have multiple engines
        enum llm_engine_type
        {
            LLAMA2_C,
            LLAMA_CPP,
            BITNET
        };
        
        // copied from https://github.com/WebAssembly/wasi-nn/blob/main/wit/wasi-nn.wit
        enum model_format 
        {
            OPENVINO,
            ONNX,
            TENSORFLOW,
            PYTORCH,
            TENSORFLOWLITE,
            GGML,
            GGUF,
            LLAMA2,
            PADDLE_PADDLE,
            CAFFE,
            MXNET
            
            AUTODETECT
        };
    
        // copied from https://github.com/WebAssembly/wasi-nn/blob/main/wit/wasi-nn.wit
        enum tensor_type 
        {
            FP16,
            FP32,       // used by the unquantised lama2.c logic
            FP64,
            BF16,
            U8,         // used by the quantised lama2.c logic
            I32,
            I64
        };      
        
        enum encryption_type
        {
            NONE,
            AES_GCM,
            AES_CTR,
            AES_ECB
        };
        
        enum hash_type
        {
            NONE            = 0,
            
            SHA1            = 1,
            
            SHA2_256        = 2,
            SHA2_384        = 3,
            SHA2_512        = 4,
            
            SHA3_256        = 5,
            SHA3_384        = 6,
            SHA3_512        = 7,
            
            MD5             = 8,
            
            CMAC_128        = 11
        };  
        
        // Allow to show a model to someone who is not logged in
        enum access
        {
            PUBLIC,
            PRIVATE
        };
        
        
        struct llm_model
        {
            static std::string table_name = "LLM_MODEL";
            
            std::string                     name;
            std::string                     local_path;
            std::string                     url;
            std::string                     description;
            llm_engine_type                 engine_type;
            std::string                   engine_config; //json::v1::map
            encryption_type                 encryption_type;
            std::string            encryption_key;
            hash_type                       hash_type;
            std::string            hash;
            bool                            is_loaded; // this indicates that a model is loaded on a node and if it is not to load it when it is required automatically
            access                          access;
            uint64_t                        inactivitiy_timeout; // miliseconds
        };
        
        struct tokenizer
        {
            // static std::string table_name = "LLM_TOKENISER";
            
            std::string                     name;
            std::string                     local_path;
            std::string                     url;
            std::string                     description;
            model_format                    model_format;
            llm_engine_type                 engine_type;
            tensor_type                     tensor_type;
            encryption_type                 encryption_type;
            std::string            encryption_key;
            hash_type                       hash_type;
            std::string            hash;
            bool                            is_loaded; 
            access                          access;
        };
        
        struct model_list_item
        {
            std::string                     name;
            std::string                     local_path;
            std::string                     url;
            std::string                     description;
            llm_engine_type                 engine_type;
            std::string                   engine_config; //json::v1::map
            encryption_type                 encryption_type;
            hash_type                       hash_type;
            std::string            hash;
            // file_system::download_status    status;
            uint64_t                        file_size;
            bool                            is_loaded;
            access                          access;
            uint64_t                        inactivitiy_timeout;
        };
        
        struct tokenizer_list_item
        {
            std::string                     name;
            std::string                     local_path;
            std::string                     url;
            std::string                     description;
            model_format                    model_format;
            llm_engine_type                 engine_type;
            tensor_type                     tensor_type;
            encryption_type                 encryption_type;
            hash_type                       hash_type;
            std::string            hash;
            // file_system::download_status    status;
            uint64_t                        file_size;
            bool                            is_loaded;
            access                          access;
        };
        
        enum role
        {
            GUEST,
            USER,
            ADMINISTRATOR
        };
        
        struct account
        {
            static std::string table_name = "ACCOUNT";

            std::string                     name; // sender
            role                            role;            
            std::string            passkey; // this is for the benefit of the file system
        }
        
        struct account_list_item
        {
            std::string                     name; // sender
            role                            role;
        };
        
        enum chat_response_state
        {
            PIECE,
            END    
        };
        
        struct chat_response_piece_binary
        {
            chat_response_state state;
            std::string piece;
        };
        
        struct chat_response_piece_string
        {
            chat_response_state state;
            std::string piece;
        };
        
        // an LLM session encapsulating interface
        interface i_context_event
        {
            int piece(const std::string& piece);
        };
        
        // an LLM session encapsulating interface
        interface i_context
        {
            int add_prompt(const std::string& prompt);
            // int get_piece([out] std::string& piece, [out] bool& complete);
            int set_callback(const rpc::shared_ptr<i_context_event>& event);
        };        
          
    }
}
